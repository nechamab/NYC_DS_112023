{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Nov 2023\n",
    "<p>Phase 3</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many classification metrics for evaluating model validation/test set performance:\n",
    "\n",
    "- Changes which model you will pick during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of evaluation metric:\n",
    "- Major impact on how well model serves its intended goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scenario: Identifying Fraudulent Credit Card Transactions\n",
    "<center><img src = \"Images/credit_card.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset contains a bunch of features:\n",
    "- The transaction amount\n",
    "- The relative time of the transaction\n",
    "- V1-V28 are relevant features: product of feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fraud transaction algorithms:\n",
    "- Typically huge number of features \n",
    "- Can create snall combination of features that encompass most variation in the full feature set:\n",
    "    - Principal component analysis (PCA)\n",
    "    - V1-V28 are these combination features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Target 'Class':\n",
    "- 1 if the transaction was fraudulent\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What have we just learned about our target in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Run a logistic regression on the credit card fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)\n",
    "X_train_sc = cred_scaler.transform(X_train)\n",
    "X_test_sc = cred_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember:\n",
    "- .score(X,y) gets the accuracy of our classification model on predicting y given X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We got 99.88% accuracy! \n",
    "- Our model is good. Right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Think again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "- Fraction of correct classifications.\n",
    "- What the `.score()` method calculates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Class 1 (Fraud) = Our positive class**\n",
    "\n",
    "- TP: True positive\n",
    "- FP: False positive\n",
    "- TN: True negative\n",
    "- FN: False negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Easy way to unpack the TP, TN, FP, FN is using the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix #nice function to visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "y_pred = cred_model.predict(X_test_sc) \n",
    "# calculate confusion matrix\n",
    "cfmat = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "cfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493 3 0 4\n",
      "[[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfmat.flatten()\n",
    "print(tn,fn,fp,tp)\n",
    "\n",
    "print(cfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, \n",
    "                      X_test_sc, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My accuracy is great. But is model doing well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "True positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positives\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model not doing well on fraud detection.\n",
    "\n",
    "But the accuracy is great. What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Accuracy is not a great metric when:\n",
    "- There's a class imbalance\n",
    "- When we care about the positive detections rate for *each* given class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A better metric (for this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In this case: \n",
    "- Of the model's prediction of 'fraudulent', how many of those predictions were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = tp/(tp+fp)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the given task of detecting credit card fraud:\n",
    "    \n",
    "Is precision something that the credit card company cares a lot about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another metric that could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "Of the actual fraudulent transactions in our data, how many did our model predict as fraudulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this task, is recall an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A metric balancing both recall and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An $F$-score is a combination of precision and recall, which can be useful when both are important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $F_1$ score is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Precision \\cdot Recall}{Precision + Recall} = \\\\ \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "f1_sc = 2*prec*rec / (prec + rec)\n",
    "print(f1_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `classification_report()`\n",
    "\n",
    "- Summary of the various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2493\n",
      "           1       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      0.79      0.86      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get precision/recall/f1-score for each class.\n",
    "- Also prints out class-averaged precision/recall/f-score.\n",
    "- Support: number of instances of each class in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another example: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Load the data and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "cancer_data_dict = load_breast_cancer()\n",
    "X_cancer = cancer_data_dict['data']\n",
    "cancer_feature_names = cancer_data_dict[\n",
    "    'feature_names']\n",
    "\n",
    "cancer_features = pd.DataFrame(X_cancer, \n",
    "                               columns = cancer_feature_names)\n",
    "cancer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/fractal_mammogram.png\" width = 600 /></center>\n",
    "<center>Feature engineering mammogram.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cancer = cancer_data_dict['target']\n",
    "cancer_data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    " - 0 = malignant\n",
    " - 1 = Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_style": "center",
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(cancer_features, y_cancer,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standard scale and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train_bc)\n",
    "X_train_sc = bc_scaler.transform(X_train_bc)\n",
    "X_test_sc = bc_scaler.transform(X_test_bc)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                           random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = bc_model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate the following for this model:\n",
    "- Use scikit-learn's functions for this\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2500, 143]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2c7908153c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2500, 143]"
     ]
    }
   ],
   "source": [
    "bc_model.score(X_test_sc, y_test)\n",
    "precision_score(y_test, y_pred)\n",
    "recall_score(y_test, y_pred)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fea85037f70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix(y_test_bc, y_pred)\n",
    "\n",
    "plot_confusion_matrix(bc_model, X_test_sc, y_test_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        54\n",
      "           1       0.99      0.98      0.98        89\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which of these metrics matter for this breast cancer detection problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Which metric to tune model hyperparameters with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Accuracy: misleading under class imbalance\n",
    "- Precision: when false positives are much worse than false negatives\n",
    "    - Spam detection (false positive sends an important email to spam)\n",
    "- Recall: when false negatives are a lot worse \n",
    "    - X-ray imaging for cancer prediction.  \n",
    "- F-score: both precision and recall important\n",
    "    - RADAR detection of enemy warplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Multiclass classification**: more than two possible values for the target. An example:\n",
    "\n",
    "- Classifying iris sub-species based on petal/sepal characteristics.\n",
    "\n",
    "<center><img src = \"Images/iris-dataset.png\" width = 500 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Same metrics/methods to evaluate our models:\n",
    "- Confusion matrices: number of rows/columns equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Metrics (precision/recall):\n",
    "    - choose one class to be the \"positive\" class.\n",
    "    - rest are assigned to the \"negative\" class. \n",
    "    - compute precision/recall for given \"positive\" class.\n",
    "\n",
    "Repeat for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = load_iris()\n",
    "X = data_dict['data']\n",
    "features = pd.DataFrame(X, columns = data_dict['feature_names'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_dict['target']\n",
    "data_dict['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 0 = setosa\n",
    "- 1 = versicolor\n",
    "- 2 = virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train-test split \n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(features, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Scale and transform\n",
    "iris_scaler = StandardScaler()\n",
    "X_train_iris_sc = iris_scaler.fit_transform(X_train_iris)\n",
    "X_test_iris_sc = iris_scaler.transform(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fit model and get predictions\n",
    "iris_model = LogisticRegression(max_iter = 10000)\n",
    "iris_model.fit(X_train_iris_sc, y_train_iris)\n",
    "y_pred_iris = iris_model.predict(X_test_iris_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_style": "split",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fea89c749a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(iris_model, X_test_iris_sc, \n",
    "                      y_test_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our confusion matrix for the multiclass iris problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.88      0.93      0.90        15\n",
      "           2       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.92      0.92        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_iris, y_pred_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some issues with assessing the quality of a model solely on these metrics:\n",
    "- Need to think a little bit more carefully about probabilities and classification thresholds\n",
    "- The reciever operation curve (up next)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
